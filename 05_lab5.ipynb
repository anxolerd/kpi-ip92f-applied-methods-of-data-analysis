{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторна робота №5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добування бажаних бізнес оглядів \n",
    "В попередньому зошиті ми досягли двох речей. \n",
    "По-перше, ми визначили категорії бізнесу (italian / Pizza), на які буде спрямована наша кампанія. \n",
    "По-друге, ми визначили ідентифікатори підприємств (business ID), пов’язані з цими категоріями. Знання business ID дозволяє вибрати  з файлу відгуків лише ті відгуки, які нас цікавлять. Перш ніж поспішати читати дані оглядів в один великий фрейм даних, щоб потім відфільтрувати лише ті ідентифікатори, які вас цікавлять, ви, як Data Scientist, спочатку  повинні отримати уявлення про розмір файлу. Файл оглядів досить великий (майже шість мільйонів рядків). Якщо у вас дуже хороший комп'ютер з великим обсягом оперативної пам’яті, або ви чомусь хочете запустити монітор системи / пам’яті і спостерігати, як вільна пам'ять падає все далі і далі, поки комп'ютер не захопить її всю, вам варто замислитися про те, як читати лише ті рядки, які нас дійсно цікавлять. Таким чином, ми будемо споживати лише мінімум необхідної оперативної пам’яті. Звичайно, загалом, навіть у цьому випадку нам  слід робити якийсь розрахунок, чи відповідає файл можливостям комп'ютера. У цьому випадку слід мати подвійний запас ресурсів для більшості сучасних комп'ютерів. Завдання цього зошита - проаналізувати файл даних з оглядами та зберегти (набагато меншу) підмножину даних, які нас власне цікавлять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries here\n",
    "None\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Список необхідних  business IDs\n",
    "Спочатку нам потрібно прочитати  список  business ID, який ми отримали раніше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task: read in our previously created file that contains the business IDs of interest\n",
    "# one line\n",
    "businesses = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важливо спочатку  зробити швидку перевірку зчитаних даних."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ми хочемо відобразити лише колонку business_id як список. Варто також зробити подвійну перевірку, чи відповідає він стовпцю business_id, наведеному вище."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_ids = businesses['business_id'].values\n",
    "print(business_ids[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фільтрування великого файлу даних фрагментами\n",
    "Файл даних з оглядами містить близько 6 мільйонів рядків. Нам немає потреби використовувати всі ці рядки. Наш загальний підхід полягає в тому, щоб прочитати файл і перевірити business_id у кожному рядку. Якщо цей ідентифікатор міститься в нашому списку розшукуваних ідентифікаторів, ми збережемо цей рядок. Це буде найшвидше, але найдорожче для пам'яті, за один раз прочитати весь файл з диску, а потім фільтрувати рядки в пам'яті. З іншого боку, найефективніше з точки зору використання пам’яті читати по одному запису за один раз, зразу ж перевіряти, чи потрібний нам цей рядок (і відкинути, якщо ні). Такий підхід буде найповільнішим. Ми можемо досягти балансу, коли будемо вибирати достатньо великий фрагмент, який все ще легко вписується в пам'ять, але при цьому нам не потрібно читати занадто багато фрагментів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convenience here, again we are accessing the data in the working directory that contains our notebooks.\n",
    "# Normal best practise is to keep your data separate, but this keeps things simple here.\n",
    "# If you're comfortable specifying a filepath to files outside of this working directory, then feel free to do so.\n",
    "# task: create a reader object for the review json file\n",
    "# Hint: use lines=True as before but add the chunksize=100000 parameter\n",
    "# one line of code here\n",
    "review_reader = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ми використовуємо магію часу для наступної комірки, не цікавлячись тим, скільки часу це потребуватиме. Якщо у вас є час і вам цікаво, ви можете поекспериментувати з розміром фрагменту і контролювати використання системної пам'яті та час, який займає робота цієї комірки. Я пропоную вам зберегти свій зошит перед запуском цієї комірки, про всяк випадок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# task: process the file one chunk at a time,\n",
    "# filter that chunk for rows with a business_id in business_ids\n",
    "# You can either do this within in a loop, having initialized an empty list,\n",
    "# or using a more pythonic list comprehension\n",
    "reviews = None\n",
    "# (this took some 24 minutes on my old i7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Після успішного виконання коду у вас є прочитані бажані огляди. Але ми ще не маємо їх у зручній DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перетворіть свої огляди в структуру DataFrame. \n",
    "Підказка: тут ви можете скористатися методом concat бібліотеки pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task convert your reviews into a DataFrame\n",
    "# one line of code here\n",
    "reviews = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Збереження даних \n",
    "Зробивши всю цю важку роботу, фільтруючи файл оглядів і задокументувавши процес у цьому зошиті, нам потрібно зберегти дані. \n",
    "Збережемо огляди структури DataFrame на csv, який назвемо \"reviews_filtered.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task: save the DataFrame to the specified file now.\n",
    "# don't forget to use index=False\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Якщо поглянути на розмір оригінального файлу json та наш новий файл csv, побачимо, що ми перейшли від 4,4 ГБ до 325 МБ. Це набагато зручніше!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Підсумок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У цьому проекті ви мали навчитися, як вирішити проблему та визначити відповідні дані, використовувати дані, щоб отримати уявлення про проблему та прийняти рішення, а потім використовувати ці знання для отримання потрібної підмножини даних з надзвичайно великого файлу. У наступному зошиті ми зануримось у ці дані."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
